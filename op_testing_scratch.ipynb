{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0b00202-e317-4366-a0d2-957a99e87d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the custom model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import my_extension_cpp\n",
    "from my_extension import (\n",
    "    CustomLinear, \n",
    "    CustomReLU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13a61970-a36a-4a19-92e2-6f06d5ac7160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True]], device='mps:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the matrix_multiply function\n",
    "a = torch.tensor(\n",
    "    [[1., 2., 3.],\n",
    "     [2., 3., 4.]]\n",
    ").to('mps')\n",
    "b = torch.tensor(\n",
    "    [[4., 5.],\n",
    "     [6., 7.],\n",
    "     [8., 9.]]\n",
    ").to('mps')\n",
    "\n",
    "result = my_extension_cpp.matrix_multiply(a, b)\n",
    "result_2 = a @ b\n",
    "\n",
    "result == result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeb1c839-f915-479e-8a12-61fb52c5c892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[40., 46.],\n",
       "        [58., 67.]], device='mps:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a20b5958-0a1f-47af-ab16-f7824ad44ac9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input must be a MPS tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m      7\u001b[0m weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Move your tensors to the appropriate device\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# = input_features#.to('mps')\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#weight = weight#.to('mps')\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Use a higher epsilon and atol because float32 is less precise than float64\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mgradcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCustomLinearFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(test)\n",
      "File \u001b[0;32m~/miniconda3/envs/test-pytorch-cpp/lib/python3.11/site-packages/torch/autograd/gradcheck.py:2051\u001b[0m, in \u001b[0;36mgradcheck\u001b[0;34m(func, inputs, eps, atol, rtol, raise_exception, check_sparse_nnz, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode, masked)\u001b[0m\n\u001b[1;32m   2049\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2050\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_gradcheck_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/test-pytorch-cpp/lib/python3.11/site-packages/torch/autograd/gradcheck.py:2073\u001b[0m, in \u001b[0;36m_gradcheck_helper\u001b[0;34m(func, inputs, eps, atol, rtol, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode, masked)\u001b[0m\n\u001b[1;32m   2070\u001b[0m tupled_inputs \u001b[38;5;241m=\u001b[39m _as_tuple(inputs)\n\u001b[1;32m   2071\u001b[0m _check_inputs(tupled_inputs)\n\u001b[0;32m-> 2073\u001b[0m func_out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtupled_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2074\u001b[0m outputs \u001b[38;5;241m=\u001b[39m _differentiable_outputs(func_out)\n\u001b[1;32m   2075\u001b[0m _check_outputs(outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/test-pytorch-cpp/lib/python3.11/site-packages/torch/autograd/function.py:539\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    538\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m     )\n",
      "File \u001b[0;32m~/repos/metal-nn-example/my_extension/wrapper.py:73\u001b[0m, in \u001b[0;36mCustomLinearFunction.forward\u001b[0;34m(ctx, input, weights)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     72\u001b[0m weights_t \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39mt()\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m---> 73\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmy_extension_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatrix_multiply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input must be a MPS tensor"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import gradcheck\n",
    "from my_extension import CustomLinearFunction  # Assuming this is your custom function\n",
    "\n",
    "# Convert to float32 for single precision\n",
    "input_features = torch.randn((10, 3), dtype=torch.float64, requires_grad=True)\n",
    "weight = torch.randn((2, 3), dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "# Move your tensors to the appropriate device\n",
    "# = input_features#.to('mps')\n",
    "#weight = weight#.to('mps')\n",
    "\n",
    "# Use a higher epsilon and atol because float32 is less precise than float64\n",
    "test = gradcheck(CustomLinearFunction.apply, (input_features, weight), eps=1e-3, atol=1e-2, raise_exception=True)\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46fb0ddc-1abe-4229-b335-83b074dae309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the Relus\n",
    "\n",
    "sr = nn.functional.relu(a)\n",
    "\n",
    "cr = my_extension_cpp.relu(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fc41e15-e25f-4a5d-8e1c-37b1803f576c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [2., 3., 4.]], device='mps:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ce1357b-ba83-4c47-a2dc-408305aba103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6, device='mps:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cr == sr).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f472bc64-9ea9-4890-9c06-39157a9cc576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2963db27-1917-4623-bde8-f56570b5451c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% wrong, and 100.0% right\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(\n",
    "    [[1., 2., 3.],\n",
    "     [2., 3., 4.],\n",
    "     [2., 3., 4.],\n",
    "     [2., 3., 4.],\n",
    "     [-2., -3., -4.],\n",
    "     [2., 3., 4.]]\n",
    ").to('mps')\n",
    "\n",
    "\n",
    "sr = nn.functional.relu(a)\n",
    "test_length = 1000\n",
    "\n",
    "wrong = []\n",
    "right = []\n",
    "for i in range(0, test_length):\n",
    "    cr = my_extension_cpp.relu(a)\n",
    "    if (cr == sr).sum() != sr.numel():\n",
    "        wrong.append(1)\n",
    "    else: \n",
    "        right.append(1)\n",
    "\n",
    "print(f\"{(len(wrong)/test_length)*100}% wrong, and {(len(right)/test_length)*100}% right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48bd6223-29a9-4740-8491-914ce696ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = my_extension_cpp.relu(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f09f62de-ea0c-497a-a492-41f4961ebac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [2., 3., 4.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], device='mps:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82194831-3e68-4431-83c0-defb521aa390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [2., 3., 4.]], device='mps:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b22a3f95-68be-4481-ac2d-cc0039551647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Settings\n",
    "num_features = 1\n",
    "num_samples = 100  # Number of data points\n",
    "noise_factor = 0.1  # Noise factor for output data\n",
    "\n",
    "# Generate data for a single feature\n",
    "inputs = torch.linspace(-1, 1, steps=num_samples).unsqueeze(1)  # Shape: [num_samples, 1]\n",
    "\n",
    "# Add a little noise to inputs\n",
    "inputs += torch.randn(inputs.shape) * noise_factor\n",
    "\n",
    "# Normalize and center the input data\n",
    "inputs_normalized = (inputs - inputs.mean()) / inputs.std()\n",
    "\n",
    "# Create a simple linear relationship (y = mx + b) with some noise\n",
    "m = torch.tensor([2.0])  # Slope\n",
    "b = torch.tensor([1.0])  # Intercept\n",
    "\n",
    "# Generate the target output with noise\n",
    "targets = m * inputs_normalized + b\n",
    "targets += torch.randn(targets.shape) * noise_factor  # Adding noise\n",
    "\n",
    "target_mean = targets.mean()\n",
    "shifted_targets = targets - target_mean\n",
    "\n",
    "# Split into training and testing sets\n",
    "train_inputs = inputs_normalized[:10]  # 80% for training\n",
    "train_outputs = shifted_targets[:10]\n",
    "test_inputs = inputs_normalized[90:]  # 20% for testing\n",
    "test_outputs = shifted_targets[90:]\n",
    "\n",
    "train_inputs = train_inputs.to('mps')\n",
    "train_outputs = train_outputs.to('mps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a19829c-0a14-4bb5-97ed-d116d74aabde",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CustomReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07801ed9-d5d7-42a0-8b6c-f39c6103c939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomReLU(MPS-based ReLU)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bab70ed-3599-40e9-b6cf-1f6b1a14f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = c(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1629d29e-dd99-40db-8d1f-4711eb301e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8692],\n",
       "        [-1.6171],\n",
       "        [-1.3498],\n",
       "        [-1.5872],\n",
       "        [-1.7129],\n",
       "        [-1.6019],\n",
       "        [-1.6590],\n",
       "        [-1.3591],\n",
       "        [-1.0200],\n",
       "        [-1.4112]], device='mps:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52416d4a-b94f-4d12-b354-7b78f1e45797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0187],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000]], device='mps:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eecaeeea-19e7-4768-ae9f-80319ed8578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4583827f-2fb9-4664-a0cd-c14104199ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = ReLU()\n",
    "r.to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e8e712d-e95c-44ca-94f6-c46b58a76d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = r(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3c4d0d9-8aea-44b9-9c84-771f8d030002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], device='mps:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27af12bf-1d28-451b-89d8-3ab1cc15f094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "950015db-addd-4441-9016-f945ed2f1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the custom model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from my_extension import CustomReLU\n",
    "\n",
    "cr = CustomReLU()\n",
    "cr.to('mps')\n",
    "\n",
    "sr = nn.LeakyReLU()\n",
    "sr.to('mps')\n",
    "\n",
    "test_input = torch.tensor([[-1., 1., -1., 1., -1]], requires_grad=True).to('mps')\n",
    "\n",
    "cr_output = cr(test_input)\n",
    "\n",
    "sr_output = sr(test_input)\n",
    "\n",
    "cr_output == sr_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98cca957-a0fb-4805-b90f-6216cd8c2501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0100,  1.0000, -0.0100,  1.0000, -0.0100]], device='mps:0',\n",
       "       grad_fn=<LeakyReluBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95bf925b-6ddc-4118-86d9-c86b608983da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are gradients equal? True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from my_extension import CustomReLU\n",
    "\n",
    "# Initialize both ReLU implementations and move them to the appropriate device\n",
    "cr = CustomReLU().to('mps')\n",
    "sr = nn.LeakyReLU().to('mps')\n",
    "\n",
    "# Prepare a test input tensor with requires_grad=True to track gradients\n",
    "test_input = torch.tensor([[-8000., 1000.6556, -.0005643, 8., 1.000]], requires_grad=True).to('mps')\n",
    "test_input.retain_grad()\n",
    "# Forward pass through CustomReLU\n",
    "cr_output = cr(test_input)\n",
    "# Perform a backward pass through CustomReLU\n",
    "cr_output.sum().backward()  # Use sum() to ensure scalar output for backward\n",
    "\n",
    "# Save the gradient of the input tensor after CustomReLU backward pass\n",
    "cr_grad = test_input.grad.clone()\n",
    "\n",
    "# Zero out gradients in test_input for a fresh backward pass\n",
    "test_input.grad.zero_()\n",
    "\n",
    "# Forward pass through PyTorch's LeakyReLU\n",
    "sr_output = sr(test_input)\n",
    "# Perform a backward pass through PyTorch's LeakyReLU\n",
    "sr_output.sum().backward()  # Use sum() to ensure scalar output for backward\n",
    "\n",
    "# Save the gradient of the input tensor after LeakyReLU backward pass\n",
    "sr_grad = test_input.grad.clone()\n",
    "\n",
    "# Compare the gradients from both backward passes\n",
    "are_gradients_equal = torch.equal(cr_grad, sr_grad)\n",
    "print(f\"Are gradients equal? {are_gradients_equal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22efda5e-63ff-43a3-a0a1-9f3746f6f04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0100, 1.0000, 0.0100, 1.0000, 1.0000]], device='mps:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96738104-6d22-4cd3-a8d2-dc4029132d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
