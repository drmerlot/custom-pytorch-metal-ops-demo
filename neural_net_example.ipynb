{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61fdf1c6-92eb-4fea-a09b-80b915f0cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to create a small pytorch neural net with the new mat multi and relu operations made in metal shader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f64454f7-9074-4e72-ac1d-aa13eb0aecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the custom model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from my_extension import (\n",
    "    CustomLinear, \n",
    "    CustomReLU\n",
    ")\n",
    "\n",
    "class CustomNeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CustomNeuralNet, self).__init__()\n",
    "        self.layer1 = CustomLinear(input_size, hidden_size)\n",
    "        self.relu = CustomReLU()\n",
    "        self.layer2 = CustomLinear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81140f15-a84b-4506-b41c-fa14a213c3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 comparing the custom net with a standard net\n",
    "class StandardNeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(StandardNeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60cd813a-50f9-4b86-86a6-9baeba6a6fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create both models\n",
    "input_size = 10\n",
    "hidden_size = 5\n",
    "output_size = 1\n",
    "\n",
    "standard_model = StandardNeuralNet(input_size, hidden_size, output_size)\n",
    "custom_model = CustomNeuralNet(input_size, hidden_size, output_size)\n",
    "\n",
    "# Move models to MPS\n",
    "standard_model.to('mps')\n",
    "custom_model.to('mps')\n",
    "\n",
    "# Create the input tensor and target on the MPS device\n",
    "input_tensor = torch.randn(1, input_size, requires_grad=True).to('mps')\n",
    "target = torch.randn(1, output_size).to('mps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0530ab28-376e-4b2d-b41b-5853abcd19b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try a forward and backward pass on both models\n",
    "\n",
    "# Forward pass through the standard model\n",
    "output_standard = standard_model(input_tensor)\n",
    "# Compute loss\n",
    "loss_standard = torch.mean((output_standard - target) ** 2)\n",
    "# Backward pass\n",
    "loss_standard.backward()\n",
    "\n",
    "# Forward pass through the custom model\n",
    "output_custom = custom_model(input_tensor)\n",
    "# Compute the same loss\n",
    "loss_custom = torch.mean((output_custom - target) ** 2)\n",
    "# Backward pass\n",
    "loss_custom.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8e5100b-4527-49f3-963b-7ff2aa1b6f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output - Standard Model: tensor([[0.2352]], device='mps:0', grad_fn=<LinearBackward0>)\n",
      "Output - Custom Model: tensor([[0.]], device='mps:0', grad_fn=<CustomLinearFunctionBackward>)\n",
      "Gradients comparison for fc1.weight: False\n",
      "Gradients comparison for fc1.bias: False\n"
     ]
    }
   ],
   "source": [
    "# Compare outputs\n",
    "print(\"Output - Standard Model:\", output_standard)\n",
    "print(\"Output - Custom Model:\", output_custom)\n",
    "\n",
    "# Compare gradients\n",
    "for (name1, param1), (name2, param2) in zip(standard_model.named_parameters(), custom_model.named_parameters()):\n",
    "    print(f\"Gradients comparison for {name1}: {torch.allclose(param1.grad, param2.grad, atol=1e-6)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "555af575-ddf3-499e-8683-f6ec08adc0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients of layer1.weight: tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [-0.1570, -0.0344,  0.2542,  0.0716,  0.1698, -0.1733, -0.1381, -0.3383,\n",
      "         -0.1458,  0.2149],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.1855,  0.0407, -0.3003, -0.0846, -0.2006,  0.2048,  0.1632,  0.3998,\n",
      "          0.1723, -0.2539],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000]], device='mps:0')\n",
      "Gradients of layer2.weight: tensor([[ 0.0000, -0.3035, -0.1962, -0.5432, -0.0349]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# look for gradients in the custom model\n",
    "for name, param in custom_model.named_parameters():\n",
    "    print(f\"Gradients of {name}: {param.grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13c5a8cb-0249-43dc-808b-f6aadd9b7e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients of fc1.weight: tensor([[-0.5128, -0.1124,  0.8300,  0.2338,  0.5545, -0.5660, -0.4510, -1.1050,\n",
      "         -0.4761,  0.7017],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.5007,  0.1097, -0.8106, -0.2283, -0.5415,  0.5528,  0.4404,  1.0791,\n",
      "          0.4649, -0.6853],\n",
      "        [ 0.4101,  0.0899, -0.6639, -0.1870, -0.4435,  0.4528,  0.3607,  0.8839,\n",
      "          0.3808, -0.5613],\n",
      "        [-0.5645, -0.1237,  0.9137,  0.2574,  0.6104, -0.6231, -0.4964, -1.2164,\n",
      "         -0.5241,  0.7725]], device='mps:0')\n",
      "Gradients of fc1.bias: tensor([-0.4654,  0.0000,  0.4545,  0.3723, -0.5123], device='mps:0')\n",
      "Gradients of fc2.weight: tensor([[-1.5046,  0.0000, -1.1051, -0.5423, -0.3172]], device='mps:0')\n",
      "Gradients of fc2.bias: tensor([-1.3956], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "for name, param in standard_model.named_parameters():\n",
    "    print(f\"Gradients of {name}: {param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa422d2a-c8a9-4d5d-ae44-a4f874f62d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/miniconda3/envs/test-pytorch-cpp/lib/python3.11/site-packages/torch/autograd/gradcheck.py:910: UserWarning: Input #0 requires gradient and is not a double precision floating point or complex. This check will likely fail if all the inputs are not of double precision floating point or complex. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "GradcheckError",
     "evalue": "Jacobian mismatch for output 0 with respect to input 0,\nnumerical:tensor([[-2.6731e+05,  1.5175e+05,  3.2534e+05,  4.5771e+05,  2.3870e+05],\n        [-5.0000e+05, -2.0117e+00, -1.4901e+00, -3.2187e+00, -6.7055e-01],\n        [-2.3269e+05, -1.5175e+05, -3.2535e+05, -4.5771e+05, -2.3870e+05],\n        [ 2.6731e+05, -1.5175e+05, -3.2534e+05, -4.5771e+05, -2.3870e+05],\n        [ 5.0000e+05,  2.0117e+00,  1.4901e+00,  3.2187e+00,  6.7055e-01]],\n       device='mps:0')\nanalytical:tensor([[0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0.]], device='mps:0')\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGradcheckError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# gradcheck requires double precision\u001b[39;00m\n\u001b[1;32m      8\u001b[0m inp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mgradcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCustomReLUFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradient check passed:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test)\n",
      "File \u001b[0;32m~/miniconda3/envs/test-pytorch-cpp/lib/python3.11/site-packages/torch/autograd/gradcheck.py:2051\u001b[0m, in \u001b[0;36mgradcheck\u001b[0;34m(func, inputs, eps, atol, rtol, raise_exception, check_sparse_nnz, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode, masked)\u001b[0m\n\u001b[1;32m   2049\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2050\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_gradcheck_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/test-pytorch-cpp/lib/python3.11/site-packages/torch/autograd/gradcheck.py:2080\u001b[0m, in \u001b[0;36m_gradcheck_helper\u001b[0;34m(func, inputs, eps, atol, rtol, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode, masked)\u001b[0m\n\u001b[1;32m   2075\u001b[0m _check_outputs(outputs)\n\u001b[1;32m   2077\u001b[0m gradcheck_fn \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m   2078\u001b[0m     _fast_gradcheck \u001b[38;5;28;01mif\u001b[39;00m fast_mode \u001b[38;5;28;01melse\u001b[39;00m _slow_gradcheck, masked\u001b[38;5;241m=\u001b[39mmasked\n\u001b[1;32m   2079\u001b[0m )\n\u001b[0;32m-> 2080\u001b[0m \u001b[43m_gradcheck_real_imag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradcheck_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtupled_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2085\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2086\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2088\u001b[0m \u001b[43m    \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_grad_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_forward_ad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_forward_ad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_backward_ad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_backward_ad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnondet_tol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnondet_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_undefined_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_undefined_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2094\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_batched_forward_grad:\n\u001b[1;32m   2097\u001b[0m     _test_batched_grad_forward_ad(func, tupled_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/test-pytorch-cpp/lib/python3.11/site-packages/torch/autograd/gradcheck.py:1482\u001b[0m, in \u001b[0;36m_gradcheck_real_imag\u001b[0;34m(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps, rtol, atol, check_grad_dtypes, check_forward_ad, check_backward_ad, nondet_tol, check_undefined_grad)\u001b[0m\n\u001b[1;32m   1469\u001b[0m         gradcheck_fn(\n\u001b[1;32m   1470\u001b[0m             real_fn,\n\u001b[1;32m   1471\u001b[0m             real_func_out,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1479\u001b[0m             complex_indices\u001b[38;5;241m=\u001b[39mcomplex_out_indices,\n\u001b[1;32m   1480\u001b[0m         )\n\u001b[1;32m   1481\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1482\u001b[0m         \u001b[43mgradcheck_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtupled_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m            \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m            \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcheck_grad_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnondet_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_forward_ad:\n\u001b[1;32m   1495\u001b[0m     complex_inp_indices \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1496\u001b[0m         i\n\u001b[1;32m   1497\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, inp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tupled_inputs)\n\u001b[1;32m   1498\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_tensor_like(inp) \u001b[38;5;129;01mand\u001b[39;00m inp\u001b[38;5;241m.\u001b[39mis_complex()\n\u001b[1;32m   1499\u001b[0m     ]\n",
      "File \u001b[0;32m~/miniconda3/envs/test-pytorch-cpp/lib/python3.11/site-packages/torch/autograd/gradcheck.py:1623\u001b[0m, in \u001b[0;36m_slow_gradcheck\u001b[0;34m(func, func_out, tupled_inputs, outputs, eps, rtol, atol, check_grad_dtypes, nondet_tol, use_forward_ad, complex_indices, test_imag, masked)\u001b[0m\n\u001b[1;32m   1621\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j, (a, n) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(analytical, numerical[i])):\n\u001b[1;32m   1622\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _allclose_with_type_promotion(a, n\u001b[38;5;241m.\u001b[39mto(a\u001b[38;5;241m.\u001b[39mdevice), rtol, atol):\n\u001b[0;32m-> 1623\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m GradcheckError(\n\u001b[1;32m   1624\u001b[0m                     _get_notallclose_msg(a, n, i, j, complex_indices, test_imag)\n\u001b[1;32m   1625\u001b[0m                 )\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mGradcheckError\u001b[0m: Jacobian mismatch for output 0 with respect to input 0,\nnumerical:tensor([[-2.6731e+05,  1.5175e+05,  3.2534e+05,  4.5771e+05,  2.3870e+05],\n        [-5.0000e+05, -2.0117e+00, -1.4901e+00, -3.2187e+00, -6.7055e-01],\n        [-2.3269e+05, -1.5175e+05, -3.2535e+05, -4.5771e+05, -2.3870e+05],\n        [ 2.6731e+05, -1.5175e+05, -3.2534e+05, -4.5771e+05, -2.3870e+05],\n        [ 5.0000e+05,  2.0117e+00,  1.4901e+00,  3.2187e+00,  6.7055e-01]],\n       device='mps:0')\nanalytical:tensor([[0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0.]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import gradcheck\n",
    "from my_extension import (\n",
    "    CustomReLUFunction\n",
    ")\n",
    "\n",
    "# gradcheck requires double precision\n",
    "inp = torch.randn(1, 5, dtype=torch.float, requires_grad=True).to('mps')\n",
    "test = gradcheck(CustomReLUFunction.apply, inp, eps=1e-6, atol=1e-4)\n",
    "print(\"Gradient check passed:\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ecdad94-5413-42cd-8216-1478700b1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchviz\n",
    "\n",
    "import torch\n",
    "from torch.autograd import gradcheck\n",
    "from my_extension import (\n",
    "    CustomReLUFunction\n",
    ")\n",
    "\n",
    "\n",
    "# x = torch.tensor(1., requires_grad=True).to('mps')\n",
    "# out = CustomReLUFunction.apply(x)\n",
    "#grad_x, = torch.autograd.grad(out, x, create_graph=True)\n",
    "#torchviz.make_dot((grad_x, x, out), {\"grad_x\": grad_x, \"x\": x, \"out\": out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a28d618b-8f3a-416b-bcc7-795aaa62950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 5, requires_grad=True).to('mps')\n",
    "\n",
    "t = CustomReLUFunction.apply(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c7f5538-fa62-4d89-ba21-b631bcbca561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.]], device='mps:0',\n",
       "       grad_fn=<CustomReLUFunctionBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96f99e29-e000-4184-9faa-23707f972174",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m grad_x, \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/test-pytorch-cpp/lib/python3.11/site-packages/torch/autograd/__init__.py:367\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    360\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    361\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly_inputs argument is deprecated and is ignored now \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(defaults to True). To accumulate gradient for other \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparts of the graph, please use torch.autograd.backward.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m     )\n\u001b[1;32m    366\u001b[0m grad_outputs_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_outputs, \u001b[38;5;28mlen\u001b[39m(t_outputs))\n\u001b[0;32m--> 367\u001b[0m grad_outputs_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_grads_batched\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    372\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[0;32m~/miniconda3/envs/test-pytorch-cpp/lib/python3.11/site-packages/torch/autograd/__init__.py:117\u001b[0m, in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    118\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m         )\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mis_floating_point:\n\u001b[1;32m    121\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    122\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for real scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "grad_x, = torch.autograd.grad(t, x, create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "838a3d7d-cf4c-4d8f-b8dc-3658367fa7f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StandardNeuralNet' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchviz\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtorchviz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstandard_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/test-pytorch-cpp/lib/python3.11/site-packages/torchviz/dot.py:163\u001b[0m, in \u001b[0;36mmake_dot\u001b[0;34m(var, params, show_attrs, show_saved, max_attr_chars)\u001b[0m\n\u001b[1;32m    161\u001b[0m         add_base_tensor(v)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     \u001b[43madd_base_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m resize_graph(dot)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dot\n",
      "File \u001b[0;32m~/miniconda3/envs/test-pytorch-cpp/lib/python3.11/site-packages/torchviz/dot.py:149\u001b[0m, in \u001b[0;36mmake_dot.<locals>.add_base_tensor\u001b[0;34m(var, color)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    148\u001b[0m seen\u001b[38;5;241m.\u001b[39madd(var)\n\u001b[0;32m--> 149\u001b[0m dot\u001b[38;5;241m.\u001b[39mnode(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(var)), \u001b[43mget_var_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m)\u001b[49m, fillcolor\u001b[38;5;241m=\u001b[39mcolor)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (var\u001b[38;5;241m.\u001b[39mgrad_fn):\n\u001b[1;32m    151\u001b[0m     add_nodes(var\u001b[38;5;241m.\u001b[39mgrad_fn)\n",
      "File \u001b[0;32m~/miniconda3/envs/test-pytorch-cpp/lib/python3.11/site-packages/torchviz/dot.py:94\u001b[0m, in \u001b[0;36mmake_dot.<locals>.get_var_name\u001b[0;34m(var, name)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name:\n\u001b[1;32m     93\u001b[0m     name \u001b[38;5;241m=\u001b[39m param_map[\u001b[38;5;28mid\u001b[39m(var)] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(var) \u001b[38;5;129;01min\u001b[39;00m param_map \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (name, size_to_str(\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m()))\n",
      "File \u001b[0;32m~/miniconda3/envs/test-pytorch-cpp/lib/python3.11/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StandardNeuralNet' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "import torchviz\n",
    "\n",
    "torchviz.make_dot(standard_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c22a3769-79d4-47ef-bc38-d4268d5da048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try some peice of networks separately. \n",
    "fc1 = nn.Linear(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37df66a4-5e77-472c-8f5d-c01335db466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.randn(1, 5, requires_grad=True).to('cpu')\n",
    "fc1 = nn.Linear(5, 5)\n",
    "x = fc1(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6979214f-5302-4908-93b3-b128712afb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2927, -0.2686, -1.0230,  1.0898,  0.0386]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd668cee-bc53-4b3a-a53e-176e69cadce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from my_extension import CustomReLU\n",
    "\n",
    "input_tensor = torch.randn(1, 5, requires_grad=True).to('mps')\n",
    "cr = CustomReLU()\n",
    "x = cr(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa3cf72a-1302-4931-ad9f-2f16bc7f6253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6064, -0.0156, -2.8058, -0.2572, -0.6120]], device='mps:0',\n",
       "       grad_fn=<CustomReLUFunctionBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36796da1-cec8-4d69-b13c-36d9c954c0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_output = torch.ones_like(x)\n",
    "x.backward(grad_output, retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0984e43-ad1a-46f7-9e70-5e4cec6f034d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6064, -0.0156, -2.8058, -0.2572, -0.6120]], device='mps:0',\n",
       "       grad_fn=<CustomReLUFunctionBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a36efe-c38d-40e2-b76e-e489a84a8f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from my_extension import CustomLinear\n",
    "\n",
    "input_tensor = torch.randn(5, 5, requires_grad=True).to('mps')\n",
    "cl = CustomLinear(5, 5).to('mps')\n",
    "x = cl(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c68dd33-a840-4bfa-a486-685ae618b2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2453, -0.1818,  0.1541, -0.0299, -0.0662],\n",
       "        [ 0.1551,  0.2177, -0.0136,  0.0114, -0.1537],\n",
       "        [ 0.9256, -1.1568,  0.7372,  0.2290,  0.4485],\n",
       "        [ 1.0097, -0.9976,  0.9373,  0.9538,  0.3853],\n",
       "        [-0.2037,  0.3990, -0.2366, -0.0811,  0.3480]], device='mps:0',\n",
       "       grad_fn=<CustomLinearFunctionBackward>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
