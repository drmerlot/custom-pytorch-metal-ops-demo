{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0b00202-e317-4366-a0d2-957a99e87d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the custom model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import custom_cpp\n",
    "from custom import (\n",
    "    CustomLinear, \n",
    "    CustomReLU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13a61970-a36a-4a19-92e2-6f06d5ac7160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True]], device='mps:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the matrix_multiply function\n",
    "a = torch.tensor(\n",
    "    [[1., 2., 3.],\n",
    "     [2., 3., 4.]]\n",
    ").to('mps')\n",
    "b = torch.tensor(\n",
    "    [[4., 5.],\n",
    "     [6., 7.],\n",
    "     [8., 9.]]\n",
    ").to('mps')\n",
    "\n",
    "result = custom_cpp.matrix_multiply(a, b)\n",
    "result_2 = a @ b\n",
    "\n",
    "result == result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeb1c839-f915-479e-8a12-61fb52c5c892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[40., 46.],\n",
       "        [58., 67.]], device='mps:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46fb0ddc-1abe-4229-b335-83b074dae309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the Relus\n",
    "\n",
    "sr = nn.functional.relu(a)\n",
    "\n",
    "cr = custom_cpp.relu(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fc41e15-e25f-4a5d-8e1c-37b1803f576c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [2., 3., 4.]], device='mps:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ce1357b-ba83-4c47-a2dc-408305aba103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6, device='mps:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cr == sr).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f472bc64-9ea9-4890-9c06-39157a9cc576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2963db27-1917-4623-bde8-f56570b5451c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% wrong, and 100.0% right\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(\n",
    "    [[1., 2., 3.],\n",
    "     [2., 3., 4.],\n",
    "     [2., 3., 4.],\n",
    "     [2., 3., 4.],\n",
    "     [-2., -3., -4.],\n",
    "     [2., 3., 4.]]\n",
    ").to('mps')\n",
    "\n",
    "b = torch.tensor(\n",
    "    [[1., 2., 3.]]\n",
    ").to('mps')\n",
    "\n",
    "b = b.unsqueeze(0)\n",
    "\n",
    "sr = a + b\n",
    "test_length = 1000\n",
    "\n",
    "wrong = []\n",
    "right = []\n",
    "for i in range(0, test_length):\n",
    "    cr = custom_cpp.matrix_add(a, b)\n",
    "    if (cr == sr).sum() != sr.numel():\n",
    "        wrong.append(1)\n",
    "    else: \n",
    "        right.append(1)\n",
    "\n",
    "print(f\"{(len(wrong)/test_length)*100}% wrong, and {(len(right)/test_length)*100}% right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac911f1a-276d-43c3-9b07-1c214a3831d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  4.,  6.],\n",
       "        [ 3.,  5.,  7.],\n",
       "        [ 3.,  5.,  7.],\n",
       "        [ 3.,  5.,  7.],\n",
       "        [-1., -1., -1.],\n",
       "        [ 3.,  5.,  7.]], device='mps:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d04b290e-71c7-4c80-ad0c-07d51c1cbfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1., 2., 3.]]).to('mps')\n",
    "cr = custom_cpp.relu(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "818445ae-b615-47fd-80fc-9682b3d95aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], device='mps:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0949a147-79c2-4864-9499-30228047e48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "            aten::copy_        96.43%       8.218ms        97.02%       8.268ms       4.134ms             2  \n",
      "           aten::select         0.93%      79.000us         1.00%      85.000us      42.500us             2  \n",
      "         aten::_to_copy         0.69%      59.000us        98.06%       8.357ms       4.178ms             2  \n",
      "        aten::expand_as         0.50%      43.000us         0.59%      50.000us      25.000us             2  \n",
      "               aten::to         0.47%      40.000us        98.53%       8.397ms       2.099ms             4  \n",
      "    aten::empty_strided         0.38%      32.000us         0.38%      32.000us      10.667us             3  \n",
      "            aten::empty         0.31%      26.000us         0.31%      26.000us      13.000us             2  \n",
      "            aten::fill_         0.13%      11.000us         0.13%      11.000us       5.500us             2  \n",
      "       aten::as_strided         0.08%       7.000us         0.08%       7.000us       1.750us             4  \n",
      "           aten::expand         0.07%       6.000us         0.08%       7.000us       3.500us             2  \n",
      "       aten::empty_like         0.01%       1.000us         0.04%       3.000us       3.000us             1  \n",
      "-----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 8.522ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-02-19 21:55:25 85160:7635471 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-02-19 21:55:25 85160:7635471 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-02-19 21:55:25 85160:7635471 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "with torch.autograd.profiler.profile() as prof:\n",
    "    output = custom_cpp.relu(a)\n",
    "print(prof.key_averages().table(sort_by=\"self_cpu_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b4f0104-7dc9-475f-a0a4-0ea1a6b2387b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<FunctionEvent id=1 name=aten::empty device_type=DeviceType.CPU node_id=-1 cpu_time=19.000us start_us=332 end_us=351 cpu_children=[] cuda_time=0.000us name=aten::empty thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=-1 is_legacy=False>, <FunctionEvent id=2 name=aten::select device_type=DeviceType.CPU node_id=-1 cpu_time=71.000us start_us=393 end_us=464 cpu_children=[3] cuda_time=0.000us name=aten::select thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=0 is_legacy=False>, <FunctionEvent id=3 name=aten::as_strided device_type=DeviceType.CPU node_id=-1 cpu_time=4.000us start_us=450 end_us=454 cpu_children=[] cuda_time=0.000us name=aten::as_strided thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=-1 is_legacy=False>, <FunctionEvent id=4 name=aten::fill_ device_type=DeviceType.CPU node_id=-1 cpu_time=8.000us start_us=501 end_us=509 cpu_children=[] cuda_time=0.000us name=aten::fill_ thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=-1 is_legacy=False>, <FunctionEvent id=5 name=aten::to device_type=DeviceType.CPU node_id=-1 cpu_time=1.000us start_us=579 end_us=580 cpu_children=[] cuda_time=0.000us name=aten::to thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=0 is_legacy=False>, <FunctionEvent id=6 name=aten::to device_type=DeviceType.CPU node_id=-1 cpu_time=8.040ms start_us=582 end_us=8622 cpu_children=[7] cuda_time=0.000us name=aten::to thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=0 is_legacy=False>, <FunctionEvent id=7 name=aten::_to_copy device_type=DeviceType.CPU node_id=-1 cpu_time=8.003ms start_us=618 end_us=8621 cpu_children=[8, 9] cuda_time=0.000us name=aten::_to_copy thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=0 is_legacy=False>, <FunctionEvent id=8 name=aten::empty_strided device_type=DeviceType.CPU node_id=-1 cpu_time=23.000us start_us=629 end_us=652 cpu_children=[] cuda_time=0.000us name=aten::empty_strided thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=-1 is_legacy=False>, <FunctionEvent id=9 name=aten::copy_ device_type=DeviceType.CPU node_id=-1 cpu_time=7.928ms start_us=688 end_us=8616 cpu_children=[10] cuda_time=0.000us name=aten::copy_ thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=-1 is_legacy=False>, <FunctionEvent id=10 name=aten::expand_as device_type=DeviceType.CPU node_id=-1 cpu_time=46.000us start_us=709 end_us=755 cpu_children=[11] cuda_time=0.000us name=aten::expand_as thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=-1 is_legacy=False>, <FunctionEvent id=11 name=aten::expand device_type=DeviceType.CPU node_id=-1 cpu_time=5.000us start_us=749 end_us=754 cpu_children=[12] cuda_time=0.000us name=aten::expand thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=-1 is_legacy=False>, <FunctionEvent id=12 name=aten::as_strided device_type=DeviceType.CPU node_id=-1 cpu_time=1.000us start_us=753 end_us=754 cpu_children=[] cuda_time=0.000us name=aten::as_strided thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=-1 is_legacy=False>, <FunctionEvent id=13 name=aten::empty device_type=DeviceType.CPU node_id=-1 cpu_time=7.000us start_us=8633 end_us=8640 cpu_children=[] cuda_time=0.000us name=aten::empty thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=-1 is_legacy=False>, <FunctionEvent id=14 name=aten::select device_type=DeviceType.CPU node_id=-1 cpu_time=14.000us start_us=8644 end_us=8658 cpu_children=[15] cuda_time=0.000us name=aten::select thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=0 is_legacy=False>, <FunctionEvent id=15 name=aten::as_strided device_type=DeviceType.CPU node_id=-1 cpu_time=2.000us start_us=8652 end_us=8654 cpu_children=[] cuda_time=0.000us name=aten::as_strided thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=-1 is_legacy=False>, <FunctionEvent id=16 name=aten::fill_ device_type=DeviceType.CPU node_id=-1 cpu_time=3.000us start_us=8661 end_us=8664 cpu_children=[] cuda_time=0.000us name=aten::fill_ thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=-1 is_legacy=False>, <FunctionEvent id=17 name=aten::to device_type=DeviceType.CPU node_id=-1 cpu_time=0.000us start_us=8667 end_us=8667 cpu_children=[] cuda_time=0.000us name=aten::to thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=0 is_legacy=False>, <FunctionEvent id=18 name=aten::to device_type=DeviceType.CPU node_id=-1 cpu_time=356.000us start_us=8669 end_us=9025 cpu_children=[19] cuda_time=0.000us name=aten::to thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=0 is_legacy=False>, <FunctionEvent id=19 name=aten::_to_copy device_type=DeviceType.CPU node_id=-1 cpu_time=354.000us start_us=8671 end_us=9025 cpu_children=[20, 21] cuda_time=0.000us name=aten::_to_copy thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=0 is_legacy=False>, <FunctionEvent id=20 name=aten::empty_strided device_type=DeviceType.CPU node_id=-1 cpu_time=7.000us start_us=8674 end_us=8681 cpu_children=[] cuda_time=0.000us name=aten::empty_strided thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=-1 is_legacy=False>, <FunctionEvent id=21 name=aten::copy_ device_type=DeviceType.CPU node_id=-1 cpu_time=340.000us start_us=8684 end_us=9024 cpu_children=[22] cuda_time=0.000us name=aten::copy_ thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=-1 is_legacy=False>, <FunctionEvent id=22 name=aten::expand_as device_type=DeviceType.CPU node_id=-1 cpu_time=4.000us start_us=8692 end_us=8696 cpu_children=[23] cuda_time=0.000us name=aten::expand_as thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=-1 is_legacy=False>, <FunctionEvent id=23 name=aten::expand device_type=DeviceType.CPU node_id=-1 cpu_time=2.000us start_us=8694 end_us=8696 cpu_children=[24] cuda_time=0.000us name=aten::expand thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=-1 is_legacy=False>, <FunctionEvent id=24 name=aten::as_strided device_type=DeviceType.CPU node_id=-1 cpu_time=0.000us start_us=8695 end_us=8695 cpu_children=[] cuda_time=0.000us name=aten::as_strided thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=-1 is_legacy=False>, <FunctionEvent id=25 name=aten::empty_like device_type=DeviceType.CPU node_id=-1 cpu_time=3.000us start_us=9061 end_us=9064 cpu_children=[26] cuda_time=0.000us name=aten::empty_like thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=-1 is_legacy=False>, <FunctionEvent id=26 name=aten::empty_strided device_type=DeviceType.CPU node_id=-1 cpu_time=2.000us start_us=9061 end_us=9063 cpu_children=[] cuda_time=0.000us name=aten::empty_strided thread=1 input_shapes=[] cpu_memory_usage=0 cuda_memory_usage=0 is_async=False is_remote=False seq_nr=-1 is_legacy=False>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48bd6223-29a9-4740-8491-914ce696ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = custom_cpp.relu(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f09f62de-ea0c-497a-a492-41f4961ebac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.]], device='mps:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b22a3f95-68be-4481-ac2d-cc0039551647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Settings\n",
    "num_features = 1\n",
    "num_samples = 100  # Number of data points\n",
    "noise_factor = 0.1  # Noise factor for output data\n",
    "\n",
    "# Generate data for a single feature\n",
    "inputs = torch.linspace(-1, 1, steps=num_samples).unsqueeze(1)  # Shape: [num_samples, 1]\n",
    "\n",
    "# Add a little noise to inputs\n",
    "inputs += torch.randn(inputs.shape) * noise_factor\n",
    "\n",
    "# Normalize and center the input data\n",
    "inputs_normalized = (inputs - inputs.mean()) / inputs.std()\n",
    "\n",
    "# Create a simple linear relationship (y = mx + b) with some noise\n",
    "m = torch.tensor([2.0])  # Slope\n",
    "b = torch.tensor([1.0])  # Intercept\n",
    "\n",
    "# Generate the target output with noise\n",
    "targets = m * inputs_normalized + b\n",
    "targets += torch.randn(targets.shape) * noise_factor  # Adding noise\n",
    "\n",
    "target_mean = targets.mean()\n",
    "shifted_targets = targets - target_mean\n",
    "\n",
    "# Split into training and testing sets\n",
    "train_inputs = inputs_normalized[:10]  # 80% for training\n",
    "train_outputs = shifted_targets[:10]\n",
    "test_inputs = inputs_normalized[90:]  # 20% for testing\n",
    "test_outputs = shifted_targets[90:]\n",
    "\n",
    "train_inputs = train_inputs.to('mps')\n",
    "train_outputs = train_outputs.to('mps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a19829c-0a14-4bb5-97ed-d116d74aabde",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CustomReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07801ed9-d5d7-42a0-8b6c-f39c6103c939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomReLU(MPS-based ReLU)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bab70ed-3599-40e9-b6cf-1f6b1a14f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = c(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1629d29e-dd99-40db-8d1f-4711eb301e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6126],\n",
       "        [-1.8104],\n",
       "        [-1.4046],\n",
       "        [-1.3656],\n",
       "        [-1.4613],\n",
       "        [-1.6235],\n",
       "        [-1.4803],\n",
       "        [-1.3303],\n",
       "        [-1.2234],\n",
       "        [-1.6529]], device='mps:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52416d4a-b94f-4d12-b354-7b78f1e45797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], device='mps:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eecaeeea-19e7-4768-ae9f-80319ed8578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4583827f-2fb9-4664-a0cd-c14104199ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = ReLU()\n",
    "r.to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e8e712d-e95c-44ca-94f6-c46b58a76d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = r(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3c4d0d9-8aea-44b9-9c84-771f8d030002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], device='mps:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27af12bf-1d28-451b-89d8-3ab1cc15f094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "950015db-addd-4441-9016-f945ed2f1daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False,  True, False]], device='mps:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the custom model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from custom import CustomReLU\n",
    "\n",
    "cr = CustomReLU()\n",
    "cr.to('mps')\n",
    "\n",
    "sr = nn.LeakyReLU()\n",
    "sr.to('mps')\n",
    "\n",
    "test_input = torch.tensor([[-1., 1., -1., 1., -1]], requires_grad=True).to('mps')\n",
    "\n",
    "cr_output = cr(test_input)\n",
    "\n",
    "sr_output = sr(test_input)\n",
    "\n",
    "cr_output == sr_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98cca957-a0fb-4805-b90f-6216cd8c2501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0100,  1.0000, -0.0100,  1.0000, -0.0100]], device='mps:0',\n",
       "       grad_fn=<LeakyReluBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95bf925b-6ddc-4118-86d9-c86b608983da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are gradients equal? False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from custom import CustomReLU\n",
    "\n",
    "# Initialize both ReLU implementations and move them to the appropriate device\n",
    "cr = CustomReLU().to('mps')\n",
    "sr = nn.LeakyReLU().to('mps')\n",
    "\n",
    "# Prepare a test input tensor with requires_grad=True to track gradients\n",
    "test_input = torch.tensor([[-8000., 1000.6556, -.0005643, 8., 1.000]], requires_grad=True).to('mps')\n",
    "test_input.retain_grad()\n",
    "# Forward pass through CustomReLU\n",
    "cr_output = cr(test_input)\n",
    "# Perform a backward pass through CustomReLU\n",
    "cr_output.sum().backward()  # Use sum() to ensure scalar output for backward\n",
    "\n",
    "# Save the gradient of the input tensor after CustomReLU backward pass\n",
    "cr_grad = test_input.grad.clone()\n",
    "\n",
    "# Zero out gradients in test_input for a fresh backward pass\n",
    "test_input.grad.zero_()\n",
    "\n",
    "# Forward pass through PyTorch's LeakyReLU\n",
    "sr_output = sr(test_input)\n",
    "# Perform a backward pass through PyTorch's LeakyReLU\n",
    "sr_output.sum().backward()  # Use sum() to ensure scalar output for backward\n",
    "\n",
    "# Save the gradient of the input tensor after LeakyReLU backward pass\n",
    "sr_grad = test_input.grad.clone()\n",
    "\n",
    "# Compare the gradients from both backward passes\n",
    "are_gradients_equal = torch.equal(cr_grad, sr_grad)\n",
    "print(f\"Are gradients equal? {are_gradients_equal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22efda5e-63ff-43a3-a0a1-9f3746f6f04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 1., 1.]], device='mps:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a20b5958-0a1f-47af-ab16-f7824ad44ac9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input must be a MPS tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 14\u001b[0m\n\u001b[1;32m      7\u001b[0m weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Move your tensors to the appropriate device\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# = input_features#.to('mps')\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#weight = weight#.to('mps')\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Use a higher epsilon and atol because float32 is less precise than float64\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mgradcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCustomLinearFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(test)\n",
      "File \u001b[0;32m~/miniconda3/envs/test-pytorch-cpp/lib/python3.11/site-packages/torch/autograd/gradcheck.py:2049\u001b[0m, in \u001b[0;36mgradcheck\u001b[0;34m(func, inputs, eps, atol, rtol, raise_exception, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode, masked)\u001b[0m\n\u001b[1;32m   2047\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2048\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_gradcheck_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/test-pytorch-cpp/lib/python3.11/site-packages/torch/autograd/gradcheck.py:2071\u001b[0m, in \u001b[0;36m_gradcheck_helper\u001b[0;34m(func, inputs, eps, atol, rtol, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode, masked)\u001b[0m\n\u001b[1;32m   2068\u001b[0m tupled_inputs \u001b[38;5;241m=\u001b[39m _as_tuple(inputs)\n\u001b[1;32m   2069\u001b[0m _check_inputs(tupled_inputs)\n\u001b[0;32m-> 2071\u001b[0m func_out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtupled_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m outputs \u001b[38;5;241m=\u001b[39m _differentiable_outputs(func_out)\n\u001b[1;32m   2073\u001b[0m _check_outputs(outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/test-pytorch-cpp/lib/python3.11/site-packages/torch/autograd/function.py:572\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m     )\n",
      "File \u001b[0;32m~/repos/custom-pytorch-metal-ops-demo/custom/custom_ops.py:46\u001b[0m, in \u001b[0;36mCustomLinearFunction.forward\u001b[0;34m(ctx, input, weights, bias)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     45\u001b[0m weights \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39mt()\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m---> 46\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmy_extension_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatrix_multiply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m     bias_2d \u001b[38;5;241m=\u001b[39m bias\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input must be a MPS tensor"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import gradcheck\n",
    "from custom import CustomLinearFunction  # Assuming this is your custom function\n",
    "\n",
    "# Convert to float32 for single precision\n",
    "input_features = torch.randn((10, 3), dtype=torch.float64, requires_grad=True)\n",
    "weight = torch.randn((2, 3), dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "# Move your tensors to the appropriate device\n",
    "# = input_features#.to('mps')\n",
    "#weight = weight#.to('mps')\n",
    "\n",
    "# Use a higher epsilon and atol because float32 is less precise than float64\n",
    "test = gradcheck(CustomLinearFunction.apply, (input_features, weight), eps=1e-3, atol=1e-2, raise_exception=True)\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96738104-6d22-4cd3-a8d2-dc4029132d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
